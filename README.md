# Deep_Voice_Classifier
Deep Voice Classifier is a machine learning project that involves training a deep neural network to classify three different classes of audio recordings: Forest Recordings, CapuchinBirds Clips, and Not CapuchinBirds Clips.

The project is built using Python and relies on popular machine learning libraries such as TensorFlow and Scikit-learn. The audio recordings are preprocessed to extract acoustic features such as pitch and spectral density, which are used to train the model.

After training the model, the performance is evaluated using spectrogram analysis. Spectrogram is a visual representation of the spectrum of frequencies of a sound or other signal as they vary with time. By visualizing the spectrogram of the audio recordings, we can get a better understanding of the features that the model is using to make predictions.

The results of the model are reported in terms of accuracy, precision, recall, and F1 score. These metrics provide insights into how well the model is performing on each of the three classes of audio recordings.

This project can be used as a starting point for developing more complex audio recognition systems, such as speech recognition or music genre classification. The trained model can be deployed as a standalone application or integrated into other software systems to classify audio recordings.
